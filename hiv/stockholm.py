import logging
import networkx as nx
import numpy as np


LOGGER = logging.getLogger(__name__)
Edge = tuple[int, int]


def get_edges(graph: nx.Graph, casual: bool) -> list[Edge]:
    """
    Get casual or steady edges.
    """
    return [
        (u, v) for u, v, data in graph.edges(data=True) if data["is_casual"] == casual
    ]


def evaluate_num_edges(graph: nx.Graph, casual: bool) -> int:
    """
    Evaluate the number of casual or steady edges.
    """
    return len(get_edges(graph, casual))


def get_nodes(graph: nx.Graph, single: bool) -> int:
    """
    Get single or paired nodes.
    """
    return [
        node for node, data in graph.nodes(data=True) if data["is_single"] == single
    ]


def evaluate_num_nodes(graph: nx.Graph, single: bool) -> int:
    """
    Evaluate the number of single or partnered nodes.
    """
    return len(get_nodes(graph, single))


def add_edges_from_candidates(
    graph: nx.Graph, candidates: np.ndarray, **kwargs
) -> np.ndarray:
    """
    Add random edges from a list of candidate nodes by pairing them. Existing edges are
    left unchanged (important for not accidentally turning steady relationships into
    casual ones).

    Args:
        graph: Graph to add edges to.
        candidates: Set of candidates to pair up.
        **kwargs: Common properties for all edges.

    Returns:
        edges: List of edges.
    """
    candidates = np.random.permutation(candidates)
    num_edges = candidates.size // 2
    candidates = candidates[: 2 * num_edges]
    edges = candidates.reshape((num_edges, 2))
    # Filter to edges that do not already exist.
    edges = np.asarray([edge for edge in edges if not graph.has_edge(*edge)])
    graph.add_edges_from(edges, **kwargs)
    return edges


def _maybe_verify_state(verify: bool, graph: nx.Graph, num_steady_edges: int) -> None:
    if not verify:
        return
    # Verify number of edges of each type.
    assert evaluate_num_edges(graph, False) == num_steady_edges
    assert graph.number_of_edges() == num_steady_edges + evaluate_num_edges(graph, True)

    # Verify status flags for each node.
    for node, data in graph.nodes(data=True):
        # Nodes that are single should have zero edges that are not casual. Nodes that
        # are paired should have exactly one edge that is not casual.
        single_degree = sum(
            not edge_data["is_casual"] for *_, edge_data in graph.edges(node, data=True)
        )
        assert (data["is_single"] and single_degree == 0) or (
            not data["is_single"] and single_degree == 1
        )
        # Nodes that have a casual relationship should have exactly one of them.
        casual_degree = sum(
            edge_data["is_casual"] for *_, edge_data in graph.edges(node, data=True)
        )
        assert (data["has_casual"] and casual_degree == 1) or (
            not data["has_casual"] and casual_degree == 0
        )


def step(
    graph: nx.Graph,
    n: float,
    mu: float,
    sigma: float,
    rho: float,
    w0: float,
    w1: float,
    verify: bool = False,
) -> tuple[nx.Graph, dict]:
    """
    Simulate the Stockholm model, a discrete time version of the model defined in
    https://doi.org/10.1016/j.epidem.2019.02.001.

    Args:
        n: Expected number of nodes.
        mu: Probability for a node to leave the population.
        sigma: Probability for a steady relationship to end.
        rho: Probability for a single node to consider a steady relationship.
        w0: Probability for a single node to consider a casual contact.
        w1: Probability for a partnered node to consider a casual contact.
        num_steps: Number of iterations.
        graph: Initial graph that is modified in-place.
        step: Step index (required to evaluate the length of steady relationships if
            graphs are generated by calling the function multiple times).

    Returns:
        Evolved graph.
    """
    label_offset = max(graph, default=-1) + 1
    num_steady_edges = evaluate_num_edges(graph, casual=False)

    # Identify nodes to be removed and evaluate the durations of steady
    # relationships.
    nodes_to_remove = [node for node in graph if np.random.binomial(1, mu)]
    num_steady_removed = 0
    for *edge, data in graph.edges(nodes_to_remove, data=True):
        if data["is_casual"]:
            graph.add_nodes_from(edge, has_casual=False)
        else:
            num_steady_edges -= 1
            graph.add_nodes_from(edge, is_single=True)
            num_steady_removed += 1
    graph.remove_nodes_from(nodes_to_remove)

    LOGGER.info(
        "removed %d nodes with %d steady edges (total steady=%d)",
        len(nodes_to_remove),
        num_steady_removed,
        num_steady_edges,
    )
    _maybe_verify_state(verify, graph, num_steady_edges)

    # Delete all casual edges and remove steady edges with probability sigma.
    edges_to_remove = []
    for *edge, data in graph.edges(data=True):
        if data["is_casual"]:
            edges_to_remove.append(edge)
            graph.add_nodes_from(edge, has_casual=False)
        elif np.random.binomial(1, sigma):
            edges_to_remove.append(edge)
            num_steady_edges -= 1
            graph.add_nodes_from(edge, is_single=True)
    graph.remove_edges_from(edges_to_remove)

    _maybe_verify_state(verify, graph, num_steady_edges)

    # Add new nodes.
    num_new_nodes = np.random.poisson(n * mu)
    graph.add_nodes_from(
        label_offset + np.arange(num_new_nodes), is_single=True, has_casual=False
    )
    label_offset += num_new_nodes

    LOGGER.info("added %d nodes (total=%d)", num_new_nodes, graph.number_of_nodes())

    # Add steady relationships.
    singles = [
        node
        for node, data in graph.nodes(data=True)
        if data["is_single"] and np.random.binomial(1, rho)
    ]
    new_steady = add_edges_from_candidates(
        graph, singles, created_at=step, is_casual=False
    )
    graph.add_nodes_from(new_steady.ravel(), is_single=False)
    num_steady_edges += len(singles) // 2

    LOGGER.info(
        "added %d steady edges (total steady=%d)",
        len(singles) // 2,
        num_steady_edges,
    )
    _maybe_verify_state(verify, graph, num_steady_edges)

    # Add casual relationships.
    candidates = [
        node
        for node, data in graph.nodes(data=True)
        if (data["is_single"] and np.random.binomial(1, w0))
        or (not data["is_single"] and np.random.binomial(1, w1))
    ]
    new_casual = add_edges_from_candidates(graph, candidates, is_casual=True)
    graph.add_nodes_from(new_casual.ravel(), has_casual=True)
    num_casual_edges = len(candidates) // 2

    LOGGER.info("added %d casual edges", num_casual_edges)
    _maybe_verify_state(verify, graph, num_steady_edges)

    return graph


def evaluate_summaries(graph0: nx.Graph, graph1: nx.Graph) -> dict[str, float]:
    """
    Evaluate summary statistics.

    Args:
        graph0: First graph observation.
        graph1: Second graph observation.

    Returns:
        summaries: Mapping of summary statistics.
    """
    steady_edges0 = set(get_edges(graph0, casual=False))
    steady_edges1 = set(get_edges(graph1, casual=False))

    # Evaluate number of nodes and nodes with casual relationships by relationship
    # status.
    num_nodes = {False: 0, True: 0}
    num_nodes_with_casual = {False: 0, True: 0}
    for graph in [graph0, graph1]:
        for _, data in graph.nodes(data=True):
            num_nodes[data["is_single"]] += 1
            num_nodes_with_casual[data["is_single"]] += data["has_casual"]

    return {
        "frac_retained_nodes": len(set(graph0) & set(graph1))
        / graph0.number_of_nodes(),
        "frac_retained_steady_edges": len(steady_edges0 & steady_edges1)
        / max(len(steady_edges0), 1),  # noqa: E131
        "frac_single_with_casual": num_nodes_with_casual[True]
        / max(num_nodes[True], 1),
        "frac_paired_with_casual": num_nodes_with_casual[False]
        / max(num_nodes[False], 1),
        "frac_paired": num_nodes[False]
        / (graph0.number_of_nodes() + graph1.number_of_nodes()),
    }
